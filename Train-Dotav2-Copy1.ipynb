{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import pydot\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from utils import vgg as nn\n",
    "from utils import roi_helpers\n",
    "from utils import losses as losses_fn\n",
    "from utils.simple_parser import get_data\n",
    "from utils import config, data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 64\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigProto = tf.compat.v1.ConfigProto()\n",
    "ConfigProto.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=ConfigProto)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "cfg = config.Config()\n",
    "\n",
    "# iteration 개수 (train: 1409, val: 456)\n",
    "cfg.num_epochs = 4 # 총 Epochs\n",
    "# cfg.rot_90 = True # default\n",
    "# cfg.use_random_brightness = True # add\n",
    "# cfg.use_vertical_flips = True # default\n",
    "# cfg.use_horizontal_flips = True # default\n",
    "cfg.num_rois = 128 # default\n",
    "cfg.std_scaling = 4 # default\n",
    "\n",
    "# TODO: the only file should to be change for other data to train\n",
    "cfg.model_path = './models/fusion_improved_last.hdf5'\n",
    "cfg.visual_model_path = './models/fusion_improved.png'\n",
    "cfg.train_label_file = 'dotav12_train_labels_not_large.txt' # txt 파일 경로 설정\n",
    "cfg.val_label_file = 'val_labels.txt' # txt 파일 경로 설정\n",
    "cfg.class_mapping = {\n",
    "    'plane': 0, \n",
    "    'ship': 1, \n",
    "    'storage-tank': 2, \n",
    "    'baseball-diamond': 3, \n",
    "    'tennis-court': 4, \n",
    "    'basketball-court': 5, \n",
    "    'ground-track-field': 6, \n",
    "    'harbor': 7, \n",
    "    'bridge': 8, \n",
    "    'large-vehicle': 9, \n",
    "    'small-vehicle': 10, \n",
    "    'helicopter': 11, \n",
    "    'roundabout': 12, \n",
    "    'soccer-ball-field': 13, \n",
    "    'swimming-pool': 14, \n",
    "    'container-crane': 15, \n",
    "    'airport': 16, \n",
    "    'helipad': 17,\n",
    "    'bg': 18,\n",
    "}\n",
    "cfg.len_class = len(cfg.class_mapping)\n",
    "\n",
    "with open(cfg.config_save_file, 'wb') as config_f:\n",
    "    pickle.dump(cfg, config_f)\n",
    "    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(cfg.config_save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "- train: 98990it (03:09)\n",
    "- valid: 28853it (01:02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "385925it [04:12, 1529.16it/s]\n",
      "28853it [01:11, 401.83it/s] \n"
     ]
    }
   ],
   "source": [
    "train_images, train_classes_count = get_data(cfg.train_label_file, cfg.class_mapping, sep=' ')\n",
    "validation_images, validation_classes_count = get_data(cfg.val_label_file, cfg.class_mapping, sep=',')\n",
    "\n",
    "with open('data/dotav2_train_images_not_large.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(train_images, file, indent='\\t')\n",
    "    \n",
    "with open('data/dotav2_train_classes_count.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(train_classes_count, file, indent='\\t')\n",
    "    \n",
    "with open('data/dotav2_validation_images.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(validation_images, file, indent='\\t')\n",
    "    \n",
    "with open('data/dotav2_validation_classes_count.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(validation_classes_count, file, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/dotav2_train_images_not_large.json', 'r', encoding='utf-8') as file:\n",
    "#     train_images = json.load(file)\n",
    "    \n",
    "# with open('data/dotav2_train_classes_count.json', 'r', encoding='utf-8') as file:\n",
    "#     train_classes_count = json.load(file)\n",
    "    \n",
    "# with open('data/dotav2_validation_images.json', 'r', encoding='utf-8') as file:\n",
    "#     validation_images = json.load(file)\n",
    "    \n",
    "# with open('data/dotav2_validation_classes_count.json', 'r', encoding='utf-8') as file:\n",
    "#     validation_classes_count = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (including bg) = 19\n",
      "==Training Num samples 1759 , images per class:\n",
      "{'airport': 252,\n",
      " 'baseball-diamond': 707,\n",
      " 'basketball-court': 760,\n",
      " 'bg': 0,\n",
      " 'bridge': 5823,\n",
      " 'container-crane': 86,\n",
      " 'ground-track-field': 640,\n",
      " 'harbor': 10820,\n",
      " 'helicopter': 1697,\n",
      " 'helipad': 22,\n",
      " 'large-vehicle': 46469,\n",
      " 'plane': 14322,\n",
      " 'roundabout': 1272,\n",
      " 'ship': 92360,\n",
      " 'small-vehicle': 183726,\n",
      " 'soccer-ball-field': 484,\n",
      " 'storage-tank': 18361,\n",
      " 'swimming-pool': 5120,\n",
      " 'tennis-court': 3004}\n",
      "==Validation Num samples 456 , images per class:\n",
      "{'airport': 0,\n",
      " 'baseball-diamond': 214,\n",
      " 'basketball-court': 132,\n",
      " 'bg': 0,\n",
      " 'bridge': 464,\n",
      " 'container-crane': 0,\n",
      " 'ground-track-field': 144,\n",
      " 'harbor': 2090,\n",
      " 'helicopter': 73,\n",
      " 'helipad': 0,\n",
      " 'large-vehicle': 4387,\n",
      " 'plane': 2531,\n",
      " 'roundabout': 179,\n",
      " 'ship': 8960,\n",
      " 'small-vehicle': 5438,\n",
      " 'soccer-ball-field': 153,\n",
      " 'storage-tank': 2888,\n",
      " 'swimming-pool': 440,\n",
      " 'tennis-court': 760}\n"
     ]
    }
   ],
   "source": [
    "print('Num classes (including bg) = {}'.format(cfg.len_class))\n",
    "\n",
    "print('==Training Num samples {} , images per class:'.format(len(train_images)))\n",
    "pprint(train_classes_count)\n",
    "\n",
    "print('==Validation Num samples {} , images per class:'.format(len(validation_images)))\n",
    "pprint(validation_classes_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    data_gen_train = data_generators.get_anchor_gt(train_images, train_classes_count, cfg, nn.get_img_output_length, mode='train')\n",
    "    data_gen_val = data_generators.get_anchor_gt(validation_images, validation_classes_count, cfg, nn.get_img_output_length, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    img_input = Input(shape=(None, None, 3), name='img_input')\n",
    "    roi_input = Input(shape=(None, 4), name='roi_input') # 4 == 점의 개수 * 2\n",
    "\n",
    "    # define the base network (resnet here, can be VGG, Inception, etc)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(cfg.anchor_box_scales) * len(cfg.anchor_box_ratios) # 3 * 3 == 9\n",
    "    rpn = nn.rpn(shared_layers, num_anchors) # rpn_out_class 2k이어야 하는데 k 반환\n",
    "    \n",
    "    # cfg.num_rois : 32\n",
    "    classifier = nn.classifier(shared_layers, roi_input, cfg.num_rois, nb_classes=cfg.len_class, trainable=True)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn[:2], name='model_rpn')\n",
    "    model_classifier = Model([img_input, roi_input], classifier, name='model_classifier')\n",
    "\n",
    "    # this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "    model_all = Model([img_input, roi_input], rpn[:2] + classifier, name='model_all')\n",
    "\n",
    "    model_rpn.compile(optimizer=Adam(lr=1e-5), \n",
    "                      loss=[losses_fn.rpn_loss_cls(num_anchors), losses_fn.rpn_loss_regr(num_anchors)])\n",
    "    \n",
    "    model_classifier.compile(optimizer=Adam(lr=1e-5),\n",
    "                             loss=[losses_fn.class_loss_cls, losses_fn.class_loss_regr(cfg.len_class - 1)],\n",
    "                             metrics={'dense_class_{}'.format(cfg.len_class): 'accuracy'})\n",
    "    \n",
    "    model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model_all, to_file=cfg.visual_model_path, show_shapes=True, \\\n",
    "#            show_layer_names=True, expand_nested=False, dpi=200)\n",
    "\n",
    "# display(Image.open(cfg.visual_model_path))\n",
    "# model_all.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = 5# len(train_images)\n",
    "val_length = 5# len(validation_images)\n",
    "num_epochs = int(cfg.num_epochs)\n",
    "\n",
    "losses = np.zeros((train_length, 5))\n",
    "val_losses = np.zeros((val_length, 5))\n",
    "best_loss = np.Inf\n",
    "\n",
    "rpn_accuracy_for_epoch = []\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in cfg.class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\n",
      " ./save_dota_aug_train/P1848_augment.png (2224, 1584, 3)\n",
      "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'\n",
      "\n",
      " ./save_dota_aug_train/P0282_augment.png (944, 1200, 3)\n",
      "\t rpn loss -> cls: 7.8367462158203125, regr: 1.8953641653060913\n",
      "\t cls loss -> cls: 2.9444386959075928, regr: 0.0, cls acc: 0.0\n",
      "0/5 [..............................] - ETA: 0s - rpn_cls: nan - rpn_regr: nan - detector_cls: nan - detector_regr: nan\n",
      " ./save_dota_aug_train/P2388_augment.png (2016, 2080, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t rpn loss -> cls: 7.900073528289795, regr: 1.9305849075317383\n",
      "\n",
      " ./save_dota_aug_train/P0652_augment.png (848, 656, 3)\n",
      "\t rpn loss -> cls: 7.677731513977051, regr: 1.309533715248108\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000157A8796B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x00000157A87D3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.9404077529907227, regr: 1.2417274713516235, cls acc: 0.921875\n",
      "2/5 [===========>..................] - ETA: 35:33 - rpn_cls: nan - rpn_regr: nan - detector_cls: nan - detector_regr: nan\n",
      " ./save_dota_aug_train/P0906_augment.png (1904, 1856, 3)\n",
      "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'\n",
      "\n",
      " ./save_dota_aug_train/P0254_augment.png (1920, 2320, 3)\n",
      "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'\n",
      "\n",
      " ./save_dota_aug_train/P8654_augment.png (1024, 1024, 3)\n",
      "\t rpn loss -> cls: 8.168936729431152, regr: 1.9613356590270996\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000157A8796B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x00000157A87D3700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.9275450706481934, regr: 0.0, cls acc: 1.0\n",
      "3/5 [=================>............] - ETA: 47:32 - rpn_cls: nan - rpn_regr: nan - detector_cls: nan - detector_regr: nan\n",
      " ./save_dota_aug_train/P2305_augment.png (560, 480, 3)\n",
      "\t rpn loss -> cls: 7.609238147735596, regr: 1.9420729875564575\n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.6\n",
      "Classifier accuracy for bounding boxes from RPN: 0.384375\n",
      "Loss RPN classifier: 4.736682891845703\n",
      "Loss RPN regression: 1.0332467079162597\n",
      "Loss Detector classifier: 1.7624783039093017\n",
      "Loss Detector regression: 0.2483454942703247\n",
      "Elapsed time: 4284.030375957489\n",
      "\t Total loss decreasetd from inf to 7.78075, saving weights\n",
      "\n",
      " ./save_dota_aug_train/P1674_augment.png (4000, 4000, 3)\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5080 - rpn_out_class_loss: 7.5087 - rpn_out_regress_loss: 1.9993\n",
      "\n",
      " ./save_dota_aug_train/P0925_augment.png (1888, 1088, 3)\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8170 - rpn_out_class_loss: 7.0740 - rpn_out_regress_loss: 1.7430\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9189 - dense_class_19_loss: 2.9189 - dense_regress_19_loss: 0.0000e+00 - dense_class_19_accuracy: 1.0000\n",
      "\t cls loss -> cls: 2.918854236602783, regr: 0.0, cls acc: 1.0\n",
      "1/5 [=====>........................] - ETA: 11:21 - rpn_cls: 0.0000e+00 - rpn_regr: 0.0000e+00 - detector_cls: 0.0000e+00 - detector_regr: 0.0000e+00\n",
      " ./save_dota_aug_train/P1739_augment.png (4000, 4000, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "\n",
    "        start_time = time.time()\n",
    "        rpn_accuracy_for_epoch = []\n",
    "        progbar = Progbar(train_length)\n",
    "        \n",
    "        for iter_num in range(train_length):\n",
    "            X, Y, img_data, cache = next(data_gen_train)\n",
    "            \n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "            print(f\"\\t rpn loss -> cls: {loss_rpn[1]}, regr: {loss_rpn[2]}\")\n",
    "            P_rpn = model_rpn.predict_on_batch(X) # (rpn cls, rpn regr)\n",
    "            result = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, 'tf', use_regr=True,\n",
    "                                            overlap_thresh=0.7,\n",
    "                                            max_boxes=256) # origin code is 300 but paper is set by 256 (128 - positive, 128 - negative)\n",
    "\n",
    "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            X2, Y1, Y2, IouS = roi_helpers.calc_iou(result, img_data, cfg, cfg.class_mapping)\n",
    "            \n",
    "            if X2 is None:\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "            \n",
    "            if len(neg_samples) > 0:\n",
    "                neg_samples = neg_samples[0]\n",
    "            else:\n",
    "                neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0:\n",
    "                pos_samples = pos_samples[0]\n",
    "            else:\n",
    "                pos_samples = []\n",
    "            \n",
    "            if len(pos_samples) < cfg.num_rois // 2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, cfg.num_rois // 2, replace=False).tolist()\n",
    "\n",
    "            if len(neg_samples) + len(selected_pos_samples) > cfg.num_rois:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "            else:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "            selected_samples = selected_pos_samples + selected_neg_samples\n",
    "            \n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, selected_samples, :]], [Y1[:, selected_samples, :], Y2[:, selected_samples, :]])\n",
    "            print(f\"\\t cls loss -> cls: {loss_class[1]}, regr: {loss_class[2]}, cls acc: {loss_class[3]}\")\n",
    "            \n",
    "            #### loss 계산 갱신\n",
    "            \n",
    "            losses[iter_num, 0] = loss_rpn[1]\n",
    "            losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "            losses[iter_num, 2] = loss_class[1]\n",
    "            losses[iter_num, 3] = loss_class[2]\n",
    "            losses[iter_num, 4] = loss_class[3]\n",
    "            \n",
    "            rpn_cls = np.mean(losses[:iter_num, 0])\n",
    "            rpn_regr = np.mean(losses[:iter_num, 1])\n",
    "            detector_cls = np.mean(losses[:iter_num, 2])\n",
    "            detector_regr = np.mean(losses[:iter_num, 3])\n",
    "\n",
    "            progbar.update(iter_num,\n",
    "                           [('rpn_cls', rpn_cls), \\\n",
    "                            ('rpn_regr', rpn_regr), \\\n",
    "                            ('detector_cls', detector_cls), \\\n",
    "                            ('detector_regr', detector_regr)])\n",
    "            if iter_num % 300 == 299:\n",
    "                model_all.save_weights(os.path.join('models', f'Epoch_{epoch_num}_Iter_{iter_num}_rpnCls_{rpn_cls:.4f}_rpnRegr_{rpn_regr:.4f}_clsCls_{detector_cls:.4f}_clsRegr_{detector_regr:.4f}.hdf5'))\n",
    "\n",
    "        loss_rpn_cls = np.mean(losses[:, 0])\n",
    "        loss_rpn_regr = np.mean(losses[:, 1])\n",
    "        loss_class_cls = np.mean(losses[:, 2])\n",
    "        loss_class_regr = np.mean(losses[:, 3])\n",
    "        class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "        mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\n",
    "        if cfg.verbose:\n",
    "            print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes.')\n",
    "                print('Check RPN settings or keep training.')\n",
    "                \n",
    "            print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "            print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "            print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "            print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "            print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "            print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "        curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "\n",
    "        if curr_loss < best_loss:\n",
    "            print(f'\\t Total loss decreasetd from {best_loss:.5f} to {curr_loss:.5f}, saving weights')\n",
    "            best_loss = curr_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Validation Check\n",
    "        \n",
    "        start_time = time.time()\n",
    "        rpn_accuracy_for_epoch = []\n",
    "        progbar = Progbar(val_length)\n",
    "                    \n",
    "        for iter_num in range(val_length):\n",
    "            X, Y, img_data, cache = next(data_gen_train)\n",
    "            \n",
    "            loss_rpn = model_rpn.evaluate(X, Y)\n",
    "            P_rpn = model_rpn.predict_on_batch(X)\n",
    "            result = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, 'tf', use_regr=True,\n",
    "                                            overlap_thresh=0.7,\n",
    "                                            max_boxes=256) # origin code is 300 but paper is set by 256 (128 - positive, 128 - negative)\n",
    "\n",
    "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            X2, Y1, Y2, IouS = roi_helpers.calc_iou(result, img_data, cfg, cfg.class_mapping)\n",
    "            \n",
    "            if X2 is None:\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "\n",
    "            selected_samples = np.where(Y1[0, :, -1] == 0)\n",
    "            rpn_accuracy_for_epoch.append((len(selected_samples)))\n",
    "            loss_class = model_classifier.evaluate([X, X2[:, selected_samples, :]], [Y1[:, selected_samples, :], Y2[:, selected_samples, :]])\n",
    "            \n",
    "            #### loss 계산 갱신\n",
    "            \n",
    "            val_losses[iter_num, 0] = loss_rpn[1]\n",
    "            val_losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "            val_losses[iter_num, 2] = loss_class[1]\n",
    "            val_losses[iter_num, 3] = loss_class[2]\n",
    "            val_losses[iter_num, 4] = loss_class[3]\n",
    "            \n",
    "            rpn_cls = np.mean(val_losses[:iter_num, 0])\n",
    "            rpn_regr = np.mean(val_losses[:iter_num, 1])\n",
    "            detector_cls = np.mean(val_losses[:iter_num, 2])\n",
    "            detector_regr = np.mean(val_losses[:iter_num, 3])\n",
    "\n",
    "            progbar.update(iter_num,\n",
    "                           [('rpn_cls', rpn_cls), \\\n",
    "                            ('rpn_regr', rpn_regr), \\\n",
    "                            ('detector_cls', detector_cls), \\\n",
    "                            ('detector_regr', detector_regr)])        \n",
    "        \n",
    "        \n",
    "        loss_rpn_cls = np.mean(val_losses[:, 0])\n",
    "        loss_rpn_regr = np.mean(val_losses[:, 1])\n",
    "        loss_class_cls = np.mean(val_losses[:, 2])\n",
    "        loss_class_regr = np.mean(val_losses[:, 3])\n",
    "        class_acc = np.mean(val_losses[:, 4])\n",
    "\n",
    "        mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\n",
    "        print('Val Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "        if mean_overlapping_bboxes == 0:\n",
    "            print('Val RPN is not producing bounding boxes that overlap the ground truth boxes.')\n",
    "            print('Val Check RPN settings or keep training.')\n",
    "\n",
    "        print('Val Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "        print('Val Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "        print('Val Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "        print('Val Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "        print('Val Loss Detector regression: {}'.format(loss_class_regr))\n",
    "        print('Val Elapsed time: {}'.format(time.time() - start_time))\n",
    "        \n",
    "        model_all.save_weights(os.path.join('models', f'Epoch_{epoch_num}_rpnCls_{loss_rpn_cls:.4f}_rpnRegr_{loss_rpn_regr:.4f}_clsCls_{loss_class_cls:.4f}_clsRegr_{loss_class_regr:.4f}.hdf5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ./save_dota_aug_train/P1848_augment.png (2224, 1584, 3)\n",
    "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'\n",
    "\n",
    " ./save_dota_aug_train/P0282_augment.png (944, 1200, 3)\n",
    "\t rpn loss -> cls: 7.8367462158203125, regr: 1.8953641653060913\n",
    "\t cls loss -> cls: 2.9444386959075928, regr: 0.0, cls acc: 0.0\n",
    "0/5 [..............................] - ETA: 0s - rpn_cls: nan - rpn_regr: nan - detector_cls: nan - detector_regr: nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import pydot\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from utils import vgg as nn\n",
    "from utils import roi_helpers\n",
    "from utils import losses as losses_fn\n",
    "from utils.simple_parser import get_data\n",
    "from utils import config, data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 64\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigProto = tf.compat.v1.ConfigProto()\n",
    "ConfigProto.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=ConfigProto)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "cfg = config.Config()\n",
    "\n",
    "# iteration 개수 (train: 1409, val: 456)\n",
    "cfg.num_epochs = 4 # 총 Epochs\n",
    "# cfg.rot_90 = True # default\n",
    "# cfg.use_random_brightness = True # add\n",
    "# cfg.use_vertical_flips = True # default\n",
    "# cfg.use_horizontal_flips = True # default\n",
    "cfg.num_rois = 128 # default\n",
    "cfg.std_scaling = 4 # default\n",
    "\n",
    "# TODO: the only file should to be change for other data to train\n",
    "cfg.model_path = './models/fusion_improved_last.hdf5'\n",
    "cfg.visual_model_path = './models/fusion_improved.png'\n",
    "cfg.train_label_file = 'dotav12_train_label_change_new.txt'\n",
    "cfg.val_label_file = 'val_labels.txt' # txt 파일 경로 설정\n",
    "cfg.class_mapping = {\n",
    "    'plane': 0, \n",
    "    'ship': 1, \n",
    "    'storage-tank': 2, \n",
    "    'baseball-diamond': 3, \n",
    "    'tennis-court': 4, \n",
    "    'basketball-court': 5, \n",
    "    'ground-track-field': 6, \n",
    "    'harbor': 7, \n",
    "    'bridge': 8, \n",
    "    'large-vehicle': 9, \n",
    "    'small-vehicle': 10, \n",
    "    'helicopter': 11, \n",
    "    'roundabout': 12, \n",
    "    'soccer-ball-field': 13, \n",
    "    'swimming-pool': 14, \n",
    "    'container-crane': 15, \n",
    "    'airport': 16, \n",
    "    'helipad': 17,\n",
    "    'bg': 18,\n",
    "}\n",
    "cfg.len_class = len(cfg.class_mapping)\n",
    "\n",
    "with open(cfg.config_save_file, 'wb') as config_f:\n",
    "    pickle.dump(cfg, config_f)\n",
    "    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(cfg.config_save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "- train: 98990it (03:09)\n",
    "- valid: 28853it (01:02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = 'dotav12_train_label_change_new'\n",
    "train_classes_count_name = f'{train_name}_classes_count'\n",
    "\n",
    "validation_name = 'dotav2_validation'\n",
    "validation_classes_count_name = f'{validation_name}_classes_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images, train_classes_count = get_data(cfg.train_label_file, cfg.class_mapping, sep=' ')\n",
    "# validation_images, validation_classes_count = get_data(cfg.val_label_file, cfg.class_mapping, sep=',')\n",
    "\n",
    "# with open(f'{train_name}.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(train_images, file, indent='\\t')\n",
    "\n",
    "# with open(f'{train_classes_count_name}.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(train_classes_count, file, indent='\\t')\n",
    "\n",
    "# with open(f'{validation_name}.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(validation_images, file, indent='\\t')\n",
    "\n",
    "# with open(f'{validation_classes_count_name}.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(validation_classes_count, file, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{train_name}.json', 'r', encoding='utf-8') as file:\n",
    "    train_images = json.load(file)\n",
    "\n",
    "with open(f'{train_classes_count_name}.json', 'r', encoding='utf-8') as file:\n",
    "    train_classes_count = json.load(file)\n",
    "\n",
    "with open(f'{validation_name}.json', 'r', encoding='utf-8') as file:\n",
    "    validation_images = json.load(file)\n",
    "\n",
    "with open(f'{validation_classes_count_name}.json', 'r', encoding='utf-8') as file:\n",
    "    validation_classes_count = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (including bg) = 19\n",
      "==Training Num samples 1409 , images per class:\n",
      "{'airport': 0,\n",
      " 'baseball-diamond': 419,\n",
      " 'basketball-court': 525,\n",
      " 'bg': 0,\n",
      " 'bridge': 3825,\n",
      " 'container-crane': 0,\n",
      " 'ground-track-field': 339,\n",
      " 'harbor': 6529,\n",
      " 'helicopter': 648,\n",
      " 'helipad': 0,\n",
      " 'large-vehicle': 18733,\n",
      " 'plane': 8733,\n",
      " 'roundabout': 521,\n",
      " 'ship': 38832,\n",
      " 'small-vehicle': 39340,\n",
      " 'soccer-ball-field': 410,\n",
      " 'storage-tank': 11453,\n",
      " 'swimming-pool': 1954,\n",
      " 'tennis-court': 2399}\n",
      "==Validation Num samples 456 , images per class:\n",
      "{'airport': 0,\n",
      " 'baseball-diamond': 214,\n",
      " 'basketball-court': 132,\n",
      " 'bg': 0,\n",
      " 'bridge': 464,\n",
      " 'container-crane': 0,\n",
      " 'ground-track-field': 144,\n",
      " 'harbor': 2090,\n",
      " 'helicopter': 73,\n",
      " 'helipad': 0,\n",
      " 'large-vehicle': 4387,\n",
      " 'plane': 2531,\n",
      " 'roundabout': 179,\n",
      " 'ship': 8960,\n",
      " 'small-vehicle': 5438,\n",
      " 'soccer-ball-field': 153,\n",
      " 'storage-tank': 2888,\n",
      " 'swimming-pool': 440,\n",
      " 'tennis-court': 760}\n"
     ]
    }
   ],
   "source": [
    "print('Num classes (including bg) = {}'.format(cfg.len_class))\n",
    "\n",
    "print('==Training Num samples {} , images per class:'.format(len(train_images)))\n",
    "pprint(train_classes_count)\n",
    "\n",
    "print('==Validation Num samples {} , images per class:'.format(len(validation_images)))\n",
    "pprint(validation_classes_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    data_gen_train = data_generators.get_anchor_gt(train_images, train_classes_count, cfg, nn.get_img_output_length, mode='train')\n",
    "    data_gen_val = data_generators.get_anchor_gt(validation_images, validation_classes_count, cfg, nn.get_img_output_length, mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    img_input = Input(shape=(None, None, 3), name='img_input')\n",
    "    roi_input = Input(shape=(None, 4), name='roi_input') # 4 == 점의 개수 * 2\n",
    "\n",
    "    # define the base network (resnet here, can be VGG, Inception, etc)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(cfg.anchor_box_scales) * len(cfg.anchor_box_ratios) # 3 * 3 == 9\n",
    "    rpn = nn.rpn(shared_layers, num_anchors) # rpn_out_class 2k이어야 하는데 k 반환\n",
    "    \n",
    "    # cfg.num_rois : 32\n",
    "    classifier = nn.classifier(shared_layers, roi_input, cfg.num_rois, nb_classes=cfg.len_class, trainable=True)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn[:2], name='model_rpn')\n",
    "    model_classifier = Model([img_input, roi_input], classifier, name='model_classifier')\n",
    "\n",
    "    # this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "    model_all = Model([img_input, roi_input], rpn[:2] + classifier, name='model_all')\n",
    "\n",
    "    model_rpn.compile(optimizer=Adam(lr=1e-5), \n",
    "                      loss=[losses_fn.rpn_loss_cls(num_anchors), losses_fn.rpn_loss_regr(num_anchors)])\n",
    "    \n",
    "    model_classifier.compile(optimizer=Adam(lr=1e-5),\n",
    "                             loss=[losses_fn.class_loss_cls, losses_fn.class_loss_regr(cfg.len_class - 1)],\n",
    "                             metrics={'dense_class_{}'.format(cfg.len_class): 'accuracy'})\n",
    "    \n",
    "    model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1409 456 4\n"
     ]
    }
   ],
   "source": [
    "historys = pd.DataFrame(columns=['rpn_cls', 'rpn_regr', 'detector_cls', 'detector_regr'])\n",
    "train_length = len(train_images)\n",
    "val_length = len(validation_images)\n",
    "num_epochs = int(cfg.num_epochs)\n",
    "print(train_length, val_length, num_epochs)\n",
    "\n",
    "losses = np.zeros((train_length, 5))\n",
    "val_losses = np.zeros((val_length, 5))\n",
    "best_loss = np.Inf\n",
    "\n",
    "rpn_accuracy_for_epoch = []\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in cfg.class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\n",
      " ./save_dota_aug_train_change/P0000_augment.png (5504, 3888, 3)\n",
      "\t rpn loss -> cls: 7.864053249359131, regr: 1.9811793565750122\n",
      "\n",
      " ./save_dota_aug_train_change/P0001_augment.png (5776, 1264, 3)\n",
      "\t rpn loss -> cls: 7.609644889831543, regr: 1.5934219360351562\n",
      "\n",
      " ./save_dota_aug_train_change/P0002_augment.png (2096, 2560, 3)\n",
      "\t rpn loss -> cls: 7.691080093383789, regr: 1.78555428981781\n",
      "\t cls loss -> cls: 2.9444386959075928, regr: 0.0, cls acc: 0.0\n",
      "   2/1409 [..............................] - ETA: 239:52:48 - rpn_cls: 2.5637 - rpn_regr: 0.5952 - detector_cls: 0.9815 - detector_regr: 0.0000e+00\n",
      " ./save_dota_aug_train_change/P0005_augment.png (992, 896, 3)\n",
      "\t rpn loss -> cls: 7.677186489105225, regr: 1.6817430257797241\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x000002DB29DCA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.934804916381836, regr: 0.0, cls acc: 1.0\n",
      "   3/1409 [..............................] - ETA: 166:24:00 - rpn_cls: 2.9898 - rpn_regr: 0.6857 - detector_cls: 1.1443 - detector_regr: 0.0000e+00\n",
      " ./save_dota_aug_train_change/P0008_augment.png (1248, 1152, 3)\n",
      "\t rpn loss -> cls: 7.43931770324707, regr: 1.6184173822402954\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x000002DB29DCA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.916548252105713, regr: 0.0, cls acc: 1.0\n",
      "   4/1409 [..............................] - ETA: 130:29:23 - rpn_cls: 3.3827 - rpn_regr: 0.7686 - detector_cls: 1.2980 - detector_regr: 0.0000e+00\n",
      " ./save_dota_aug_train_change/P0010_augment.png (1872, 1856, 3)\n",
      "\t rpn loss -> cls: 6.544649600982666, regr: 1.8260209560394287\n",
      "\t cls loss -> cls: 2.9003615379333496, regr: 0.0, cls acc: 1.0\n",
      "   5/1409 [..............................] - ETA: 123:11:13 - rpn_cls: 3.6846 - rpn_regr: 0.8453 - detector_cls: 1.4283 - detector_regr: 0.0000e+00\n",
      " ./save_dota_aug_train_change/P0011_augment.png (1536, 1376, 3)\n",
      "\t rpn loss -> cls: 6.518715858459473, regr: 1.6834461688995361\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000002DB29DCA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.8809804916381836, regr: 1.2189075946807861, cls acc: 0.734375\n",
      "   6/1409 [..............................] - ETA: 109:43:41 - rpn_cls: 3.9246 - rpn_regr: 0.9090 - detector_cls: 1.5373 - detector_regr: 0.0290    \n",
      " ./save_dota_aug_train_change/P0012_augment.png (2000, 2896, 3)\n",
      "\t rpn loss -> cls: 5.612185955047607, regr: 1.446419358253479\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000002DB29DCA5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\t cls loss -> cls: 2.7952396869659424, regr: 1.2865160703659058, cls acc: 0.8515625\n",
      "   7/1409 [..............................] - ETA: 120:32:49 - rpn_cls: 4.1047 - rpn_regr: 0.9585 - detector_cls: 1.6279 - detector_regr: 0.0696\n",
      " ./save_dota_aug_train_change/P0013_augment.png (1776, 1344, 3)\n",
      "\t rpn loss -> cls: 4.707335948944092, regr: 1.5035347938537598\n",
      "\t cls loss -> cls: 2.7108278274536133, regr: 1.1047139167785645, cls acc: 0.9140625\n",
      "   8/1409 [..............................] - ETA: 111:19:00 - rpn_cls: 4.2331 - rpn_regr: 0.9990 - detector_cls: 1.7033 - detector_regr: 0.1111\n",
      " ./save_dota_aug_train_change/P0018_augment.png (1696, 1824, 3)\n",
      "\t rpn loss -> cls: 4.7585978507995605, regr: 1.9008591175079346\n",
      "\t cls loss -> cls: 2.653303623199463, regr: 1.2083332538604736, cls acc: 0.9765625\n",
      "   9/1409 [..............................] - ETA: 105:13:41 - rpn_cls: 4.3289 - rpn_regr: 1.0374 - detector_cls: 1.7667 - detector_regr: 0.1523\n",
      " ./save_dota_aug_train_change/P0020_augment.png (4448, 5072, 3)\n",
      "\t rpn loss -> cls: 6.584078311920166, regr: 1.8949005603790283\n",
      "\n",
      " ./save_dota_aug_train_change/P0021_augment.png (3248, 2880, 3)\n",
      "\t rpn loss -> cls: 8.3333101272583, regr: 1.2606027126312256\n",
      "\t cls loss -> cls: 2.3318638801574707, regr: 1.1736705303192139, cls acc: 0.921875\n",
      "  11/1409 [..............................] - ETA: 108:45:08 - rpn_cls: 4.4400 - rpn_regr: 1.0716 - detector_cls: 1.8253 - detector_regr: 0.2154\n",
      " ./save_dota_aug_train_change/P0022_augment.png (6544, 3952, 3)\n",
      "\t rpn loss -> cls: 8.189800262451172, regr: 1.877807855606079\n",
      "\t cls loss -> cls: 1.8750948905944824, regr: 1.5950974225997925, cls acc: 0.9921875\n",
      "  12/1409 [..............................] - ETA: 117:34:09 - rpn_cls: 4.5025 - rpn_regr: 1.0886 - detector_cls: 1.8459 - detector_regr: 0.2461\n",
      " ./save_dota_aug_train_change/P0023_augment.png (5120, 2416, 3)\n",
      "\t rpn loss -> cls: 10.110769271850586, regr: 1.595418095588684\n",
      "\t cls loss -> cls: 1.2683688402175903, regr: 0.0, cls acc: 1.0\n",
      "  13/1409 [..............................] - ETA: 123:21:51 - rpn_cls: 4.5825 - rpn_regr: 1.1048 - detector_cls: 1.8589 - detector_regr: 0.2688\n",
      " ./save_dota_aug_train_change/P0025_augment.png (4112, 4576, 3)\n",
      "\t rpn loss -> cls: 3.9337093830108643, regr: 1.8133796453475952\n",
      "\n",
      " ./save_dota_aug_train_change/P0029_augment.png (2416, 2768, 3)\n",
      "\t rpn loss -> cls: 2.4829206466674805, regr: 1.2754462957382202\n",
      "\t cls loss -> cls: 1.3350263833999634, regr: 0.0, cls acc: 1.0\n",
      "  15/1409 [..............................] - ETA: 123:06:53 - rpn_cls: 4.6387 - rpn_regr: 1.1196 - detector_cls: 1.8573 - detector_regr: 0.2962\n",
      " ./save_dota_aug_train_change/P0030_augment.png (2416, 2768, 3)\n",
      "\t rpn loss -> cls: 2.6693780422210693, regr: 1.8853578567504883\n",
      "\t cls loss -> cls: 0.7137598395347595, regr: 0.0, cls acc: 1.0\n",
      "  16/1409 [..............................] - ETA: 128:22:19 - rpn_cls: 4.6530 - rpn_regr: 1.1281 - detector_cls: 1.8525 - detector_regr: 0.3056\n",
      " ./save_dota_aug_train_change/P0032_augment.png (1696, 2432, 3)\n",
      "\t rpn loss -> cls: 5.291608810424805, regr: 1.6062631607055664\n",
      "\n",
      " ./save_dota_aug_train_change/P0036_augment.png (5552, 3200, 3)\n",
      "\t rpn loss -> cls: 3.6566951274871826, regr: 1.7714059352874756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ./save_dota_aug_train_change/P0038_augment.png (4320, 2560, 3)\n",
      "\t rpn loss -> cls: 7.672197341918945, regr: 1.5559089183807373\n",
      "\t cls loss -> cls: 0.04507136344909668, regr: 0.0, cls acc: 1.0\n",
      "  19/1409 [..............................] - ETA: 124:13:32 - rpn_cls: 4.6320 - rpn_regr: 1.1307 - detector_cls: 1.7992 - detector_regr: 0.3172\n",
      " ./save_dota_aug_train_change/P0039_augment.png (3664, 3600, 3)\n",
      "\t rpn loss -> cls: 4.730466365814209, regr: 1.9264658689498901\n",
      "\t cls loss -> cls: 0.10104075074195862, regr: 0.0, cls acc: 1.0\n",
      "  20/1409 [..............................] - ETA: 140:39:25 - rpn_cls: 4.6269 - rpn_regr: 1.1333 - detector_cls: 1.7817 - detector_regr: 0.3194\n",
      " ./save_dota_aug_train_change/P0041_augment.png (2336, 3200, 3)\n",
      "\t rpn loss -> cls: 4.540389060974121, regr: 1.8668243885040283\n",
      "\n",
      " ./save_dota_aug_train_change/P0042_augment.png (2240, 1904, 3)\n",
      "\t rpn loss -> cls: 4.337307453155518, regr: 1.838014841079712\n",
      "\n",
      " ./save_dota_aug_train_change/P0044_augment.png (1744, 1648, 3)\n",
      "\t rpn loss -> cls: 2.079087018966675, regr: 1.6655722856521606\n",
      "\n",
      " ./save_dota_aug_train_change/P0049_augment.png (2000, 1632, 3)\n",
      "\t rpn loss -> cls: 9.151763916015625, regr: 1.3232139348983765\n",
      "\t cls loss -> cls: 0.05378762260079384, regr: 0.0, cls acc: 1.0\n",
      "  24/1409 [..............................] - ETA: 125:28:33 - rpn_cls: 4.5510 - rpn_regr: 1.1187 - detector_cls: 1.6878 - detector_regr: 0.3168\n",
      " ./save_dota_aug_train_change/P0050_augment.png (3136, 2560, 3)\n",
      "\t rpn loss -> cls: 9.379237174987793, regr: 1.6941715478897095\n",
      "\t cls loss -> cls: 0.2136930525302887, regr: 1.8459457159042358, cls acc: 0.9765625\n",
      "  25/1409 [..............................] - ETA: 124:47:09 - rpn_cls: 4.5439 - rpn_regr: 1.1168 - detector_cls: 1.6675 - detector_regr: 0.3186\n",
      " ./save_dota_aug_train_change/P0052_augment.png (2288, 1872, 3)\n",
      "\t rpn loss -> cls: 5.417758464813232, regr: 1.762647032737732\n",
      "\n",
      " ./save_dota_aug_train_change/P0054_augment.png (2112, 2192, 3)\n",
      "\t rpn loss -> cls: 3.642422676086426, regr: 1.7441990375518799\n",
      "\n",
      " ./save_dota_aug_train_change/P0058_augment.png (1200, 1216, 3)\n",
      "\t rpn loss -> cls: 4.406539440155029, regr: 1.3674203157424927\n",
      "\t cls loss -> cls: 5.443587269837735e-07, regr: 0.0, cls acc: 1.0\n",
      "  28/1409 [..............................] - ETA: 119:15:55 - rpn_cls: 4.4933 - rpn_regr: 1.1051 - detector_cls: 1.6021 - detector_regr: 0.3193\n",
      " ./save_dota_aug_train_change/P0061_augment.png (1824, 1968, 3)\n",
      "\t rpn loss -> cls: 3.9514389038085938, regr: 1.9076778888702393\n",
      "\t cls loss -> cls: 4.135075357680762e-07, regr: 0.0, cls acc: 1.0\n",
      "  29/1409 [..............................] - ETA: 117:53:06 - rpn_cls: 4.4786 - rpn_regr: 1.1027 - detector_cls: 1.5822 - detector_regr: 0.3192\n",
      " ./save_dota_aug_train_change/P0063_augment.png (2992, 2912, 3)\n",
      "\t rpn loss -> cls: 3.5944581031799316, regr: 1.8922547101974487\n",
      "\t cls loss -> cls: 1.1920928955078125e-07, regr: 0.0, cls acc: 1.0\n",
      "  30/1409 [..............................] - ETA: 124:28:00 - rpn_cls: 4.4644 - rpn_regr: 1.1015 - detector_cls: 1.5624 - detector_regr: 0.3187\n",
      " ./save_dota_aug_train_change/P0064_augment.png (2208, 2976, 3)\n",
      "\t rpn loss -> cls: 2.706742286682129, regr: 1.890864610671997\n",
      "\t cls loss -> cls: 1.5972183575740928e-07, regr: 0.0, cls acc: 1.0\n",
      "  31/1409 [..............................] - ETA: 127:11:58 - rpn_cls: 4.4497 - rpn_regr: 1.1011 - detector_cls: 1.5429 - detector_regr: 0.3179\n",
      " ./save_dota_aug_train_change/P0065_augment.png (3408, 2384, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "\n",
    "        start_time = time.time()\n",
    "        rpn_accuracy_for_epoch = []\n",
    "        progbar = Progbar(train_length)\n",
    "        \n",
    "        for iter_num in range(train_length):\n",
    "            X, Y, img_data, cache = next(data_gen_train)\n",
    "            \n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "            print(f\"\\t rpn loss -> cls: {loss_rpn[1]:.4f}, regr: {loss_rpn[2]:.4f}\")\n",
    "            P_rpn = model_rpn.predict_on_batch(X) # (rpn cls, rpn regr)\n",
    "            result = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, 'tf', use_regr=True,\n",
    "                                            overlap_thresh=0.7,\n",
    "                                            max_boxes=256) # origin code is 300 but paper is set by 256 (128 - positive, 128 - negative)\n",
    "\n",
    "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            X2, Y1, Y2, IouS = roi_helpers.calc_iou(result, img_data, cfg, cfg.class_mapping)\n",
    "            \n",
    "            if X2 is None:\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "            \n",
    "            if len(neg_samples) > 0:\n",
    "                neg_samples = neg_samples[0]\n",
    "            else:\n",
    "                neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0:\n",
    "                pos_samples = pos_samples[0]\n",
    "            else:\n",
    "                pos_samples = []\n",
    "            \n",
    "            if len(pos_samples) < cfg.num_rois // 2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, cfg.num_rois // 2, replace=False).tolist()\n",
    "\n",
    "            if len(neg_samples) + len(selected_pos_samples) > cfg.num_rois:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "            else:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "            selected_samples = selected_pos_samples + selected_neg_samples\n",
    "            \n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, selected_samples, :]], [Y1[:, selected_samples, :], Y2[:, selected_samples, :]])\n",
    "            print(f\"\\t cls loss -> cls: {loss_class[1]:.4f}, regr: {loss_class[2]:.4f}, cls acc: {loss_class[3]:.4f}\")\n",
    "            \n",
    "            #### loss 계산 갱신\n",
    "            \n",
    "            losses[iter_num, 0] = loss_rpn[1]\n",
    "            losses[iter_num, 1] = loss_rpn[2]\n",
    "            losses[iter_num, 2] = loss_class[1]\n",
    "            losses[iter_num, 3] = loss_class[2]\n",
    "            losses[iter_num, 4] = loss_class[3]\n",
    "            \n",
    "            rpn_cls = np.nanmean(losses[:iter_num+1, 0])\n",
    "            rpn_regr = np.nanmean(losses[:iter_num+1, 1])\n",
    "            detector_cls = np.nanmean(losses[:iter_num+1, 2])\n",
    "            detector_regr = np.nanmean(losses[:iter_num+1, 3])\n",
    "\n",
    "            progbar.update(iter_num,\n",
    "                           [('rpn_cls', rpn_cls), \\\n",
    "                            ('rpn_regr', rpn_regr), \\\n",
    "                            ('detector_cls', detector_cls), \\\n",
    "                            ('detector_regr', detector_regr)])\n",
    "            \n",
    "            historys = historys.append(dict([\n",
    "                            ('rpn_cls', rpn_cls), \\\n",
    "                            ('rpn_regr', rpn_regr), \\\n",
    "                            ('detector_cls', detector_cls), \\\n",
    "                            ('detector_regr', detector_regr)]), ignore_index=True)\n",
    "            historys.to_csv(f\"{train_name}-history.csv\")\n",
    "            \n",
    "            if iter_num % 100 == 0:\n",
    "                model_all.save_weights(os.path.join('models', f'Epoch_{epoch_num}_Iter_{iter_num:04}_rpnCls_{rpn_cls:.4f}_rpnRegr_{rpn_regr:.4f}_clsCls_{detector_cls:.4f}_clsRegr_{detector_regr:.4f}.hdf5'))\n",
    "\n",
    "        loss_rpn_cls = np.nanmean(losses[:, 0])\n",
    "        loss_rpn_regr = np.nanmean(losses[:, 1])\n",
    "        loss_class_cls = np.nanmean(losses[:, 2])\n",
    "        loss_class_regr = np.nanmean(losses[:, 3])\n",
    "        class_acc = np.nanmean(losses[:, 4])\n",
    "\n",
    "        mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\n",
    "        if cfg.verbose:\n",
    "            print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes.')\n",
    "                print('Check RPN settings or keep training.')\n",
    "                \n",
    "            print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "            print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "            print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "            print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "            print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "            print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "        curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "\n",
    "        if curr_loss < best_loss:\n",
    "            print(f'\\t Total loss decreased from {best_loss:.5f} to {curr_loss:.5f}')\n",
    "            best_loss = curr_loss\n",
    "        \n",
    "        model_all.save_weights(os.path.join('models', f'Epoch_{epoch_num}_rpnCls_{loss_rpn_cls:.4f}_rpnRegr_{loss_rpn_regr:.4f}_clsCls_{loss_class_cls:.4f}_clsRegr_{loss_class_regr:.4f}_acc{class_acc:.4f}.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start\n",
    "- 2021-04-15 14:52\n",
    "\n",
    "### Problem\n",
    "- img 전처리가 너무 오래 걸린다. (Y 값 계산)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ./save_dota_aug_train/P1848_augment.png (2224, 1584, 3)\n",
    "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'\n",
    "\n",
    " ./save_dota_aug_train/P0282_augment.png (944, 1200, 3)\n",
    "\t rpn loss -> cls: 7.8367462158203125, regr: 1.8953641653060913\n",
    "\t cls loss -> cls: 2.9444386959075928, regr: 0.0, cls acc: 0.0\n",
    "0/5 [..............................] - ETA: 0s - rpn_cls: nan - rpn_regr: nan - detector_cls: nan - detector_regr: nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

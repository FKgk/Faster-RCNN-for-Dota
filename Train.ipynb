{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from utils import vgg as nn\n",
    "from utils import roi_helpers\n",
    "from utils import losses as losses_fn\n",
    "from utils.simple_parser import get_data\n",
    "from utils import config, data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 64\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigProto = tf.compat.v1.ConfigProto()\n",
    "ConfigProto.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=ConfigProto)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n"
     ]
    }
   ],
   "source": [
    "cfg = config.Config()\n",
    "\n",
    "cfg.epoch_length = 5 # iteration 개수 (train: 1409, val: 456)\n",
    "cfg.num_epochs = 2 # 총 Epochs\n",
    "# cfg.rot_90 = True # default\n",
    "# cfg.use_random_brightness = True # add\n",
    "# cfg.use_vertical_flips = True # default\n",
    "# cfg.use_horizontal_flips = True # default\n",
    "cfg.num_rois = 128 # default\n",
    "cfg.std_scaling = 4 # default\n",
    "# cfg.base_net_weights = os.path.join('./model/', nn.get_weight_path())\n",
    "\n",
    "# TODO: the only file should to be change for other data to train\n",
    "cfg.model_path = './model/kitti_frcnn_last.hdf5'\n",
    "cfg.train_label_file = 'data/train_labels.txt'\n",
    "cfg.val_label_file = 'data/val_labels.txt'\n",
    "cfg.class_mapping = {\n",
    "    'small-vehicle': 0,\n",
    "    'large-vehicle': 1,\n",
    "    'harbor': 2,\n",
    "    'ship': 3,\n",
    "    'ground-track-field': 4,\n",
    "    'soccer-ball-field': 5,\n",
    "    'baseball-diamond': 6,\n",
    "    'swimming-pool': 7,\n",
    "    'roundabout': 8,\n",
    "    'tennis-court': 9,\n",
    "    'basketball-court': 10,\n",
    "    'plane': 11,\n",
    "    'helicopter': 12,\n",
    "    'bridge': 13,\n",
    "    'storage-tank': 14,\n",
    "    'bg': 15\n",
    "}\n",
    "cfg.len_class = len(cfg.class_mapping)\n",
    "\n",
    "with open(cfg.config_save_file, 'wb') as config_f:\n",
    "    pickle.dump(cfg, config_f)\n",
    "    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(cfg.config_save_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "- train: 98990it (03:09)\n",
    "- valid: 28853it (01:02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images, train_classes_count = get_data(cfg.train_label_file, cfg.class_mapping)\n",
    "# validation_images, validation_classes_count = get_data(cfg.val_label_file, cfg.class_mapping)\n",
    "\n",
    "# with open('data/train_images.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(train_images, file, indent='\\t')\n",
    "    \n",
    "# with open('data/train_classes_count.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(train_classes_count, file, indent='\\t')\n",
    "    \n",
    "# with open('data/validation_images.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(validation_images, file, indent='\\t')\n",
    "    \n",
    "# with open('data/validation_classes_count.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(validation_classes_count, file, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_images.json', 'r', encoding='utf-8') as file:\n",
    "    train_images = json.load(file)\n",
    "    \n",
    "with open('data/train_classes_count.json', 'r', encoding='utf-8') as file:\n",
    "    train_classes_count = json.load(file)\n",
    "    \n",
    "with open('data/validation_images.json', 'r', encoding='utf-8') as file:\n",
    "    validation_images = json.load(file)\n",
    "    \n",
    "with open('data/validation_classes_count.json', 'r', encoding='utf-8') as file:\n",
    "    validation_classes_count = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes (including bg) = 16\n",
      "==Training Num samples 1409 , images per class:\n",
      "{'baseball-diamond': 415,\n",
      " 'basketball-court': 515,\n",
      " 'bg': 0,\n",
      " 'bridge': 2047,\n",
      " 'ground-track-field': 325,\n",
      " 'harbor': 5983,\n",
      " 'helicopter': 630,\n",
      " 'large-vehicle': 16969,\n",
      " 'plane': 8055,\n",
      " 'roundabout': 399,\n",
      " 'ship': 28068,\n",
      " 'small-vehicle': 26126,\n",
      " 'soccer-ball-field': 326,\n",
      " 'storage-tank': 5029,\n",
      " 'swimming-pool': 1736,\n",
      " 'tennis-court': 2367}\n",
      "==Validation Num samples 456 , images per class:\n",
      "{'baseball-diamond': 214,\n",
      " 'basketball-court': 132,\n",
      " 'bg': 0,\n",
      " 'bridge': 464,\n",
      " 'ground-track-field': 144,\n",
      " 'harbor': 2090,\n",
      " 'helicopter': 73,\n",
      " 'large-vehicle': 4387,\n",
      " 'plane': 2531,\n",
      " 'roundabout': 179,\n",
      " 'ship': 8960,\n",
      " 'small-vehicle': 5438,\n",
      " 'soccer-ball-field': 153,\n",
      " 'storage-tank': 2888,\n",
      " 'swimming-pool': 440,\n",
      " 'tennis-court': 760}\n"
     ]
    }
   ],
   "source": [
    "print('Num classes (including bg) = {}'.format(cfg.len_class))\n",
    "\n",
    "print('==Training Num samples {} , images per class:'.format(len(train_images)))\n",
    "pprint(train_classes_count)\n",
    "\n",
    "print('==Validation Num samples {} , images per class:'.format(len(validation_images)))\n",
    "pprint(validation_classes_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainGenerator():\n",
    "#     for x, y in zip(range(10), range(10,20)):\n",
    "#         yield (x, y)\n",
    "\n",
    "# train_dataset  = tf.data.Dataset.from_generator(\n",
    "#     trainGenerator, \\\n",
    "#     (tf.int32, tf.float32), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    data_gen_train = data_generators.get_anchor_gt(train_images, train_classes_count, cfg, nn.get_img_output_length, mode='train')\n",
    "    data_gen_val = data_generators.get_anchor_gt(validation_images, validation_classes_count, cfg, nn.get_img_output_length, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, (Ycls, Yregr), aug = next(data_gen_train)\n",
    "# print(X.shape, Ycls.shape, Yregr.shape)\n",
    "# print(Ycls.sum(), Yregr.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_shape_img = (None, None, 3)\n",
    "\n",
    "    img_input = Input(shape=input_shape_img, name='img_input')\n",
    "    roi_input = Input(shape=(None, 4), name='roi_input') # 4 == 점의 개수 * 2\n",
    "\n",
    "    # define the base network (resnet here, can be VGG, Inception, etc)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(cfg.anchor_box_scales) * len(cfg.anchor_box_ratios) # 3 * 3 == 9\n",
    "    rpn = nn.rpn(shared_layers, num_anchors) # rpn_out_class 2k이어야 하는데 k 반환\n",
    "    \n",
    "    # cfg.num_rois : 32\n",
    "    classifier = nn.classifier(shared_layers, roi_input, cfg.num_rois, nb_classes=cfg.len_class, trainable=True)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn[:2], name='model_rpn')\n",
    "    model_classifier = Model([img_input, roi_input], classifier, name='model_classifier')\n",
    "\n",
    "    # this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "    model_all = Model([img_input, roi_input], rpn[:2] + classifier, name='model_all')\n",
    "\n",
    "    model_rpn.compile(optimizer=Adam(lr=1e-5), \n",
    "                      loss=[losses_fn.rpn_loss_cls(num_anchors), losses_fn.rpn_loss_regr(num_anchors)])\n",
    "    \n",
    "    model_classifier.compile(optimizer=Adam(lr=1e-5),\n",
    "                             loss=[losses_fn.class_loss_cls, losses_fn.class_loss_regr(cfg.len_class - 1)],\n",
    "                             metrics={'dense_class_{}'.format(cfg.len_class): 'accuracy'})\n",
    "    \n",
    "    model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_all\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "img_input (InputLayer)                 [(None, None, None, 3)]    0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)                  (None, None, None, 64)     1792          img_input[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)                  (None, None, None, 64)     36928         block1_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)             (None, None, None, 64)     0             block1_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)                  (None, None, None, 128)    73856         block1_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)                  (None, None, None, 128)    147584        block2_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)             (None, None, None, 128)    0             block2_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)                  (None, None, None, 256)    295168        block2_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)                  (None, None, None, 256)    590080        block3_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)                  (None, None, None, 256)    590080        block3_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)             (None, None, None, 256)    0             block3_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)                  (None, None, None, 512)    1180160       block3_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)                  (None, None, None, 512)    2359808       block4_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)                  (None, None, None, 512)    2359808       block4_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)             (None, None, None, 512)    0             block4_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)                  (None, None, None, 512)    2359808       block4_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)                  (None, None, None, 512)    2359808       block5_conv1[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)                  (None, None, None, 512)    2359808       block5_conv2[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)           (None, None, None, 512)    0             block5_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization (BatchNormalizatio (None, None, None, 256)    1024          block3_pool[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNormalizat (None, None, None, 512)    2048          block4_conv3[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNormalizat (None, None, None, 512)    2048          up_sampling2d[0][0]                     \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate (Concatenate)              (None, None, None, 1280)   0             batch_normalization[0][0]               \n",
      "                                                                                batch_normalization_1[0][0]             \n",
      "                                                                                batch_normalization_2[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "global_average_pooling2d (GlobalAverag (None, 1280)               0             concatenate[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMaxPooling (None, 1280)               0             concatenate[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "reshape (Reshape)                      (None, 1, 1, 1280)         0             global_average_pooling2d[0][0]          \n",
      "________________________________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)                    (None, 1, 1, 1280)         0             global_max_pooling2d[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "dense (Dense)                          (None, 1, 1, 160)          204960        reshape[0][0]                           \n",
      "                                                                                reshape_1[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                        (None, 1, 1, 1280)         206080        dense[0][0]                             \n",
      "                                                                                dense[1][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "add (Add)                              (None, 1, 1, 1280)         0             dense_1[0][0]                           \n",
      "                                                                                dense_1[1][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "activation (Activation)                (None, 1, 1, 1280)         0             add[0][0]                               \n",
      "________________________________________________________________________________________________________________________\n",
      "multiply (Multiply)                    (None, None, None, 1280)   0             concatenate[0][0]                       \n",
      "                                                                                activation[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "lambda (Lambda)                        (None, None, None, 1)      0             multiply[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                      (None, None, None, 1)      0             multiply[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)            (None, None, None, 2)      0             lambda[0][0]                            \n",
      "                                                                                lambda_1[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                        (None, None, None, 1)      98            concatenate_1[0][0]                     \n",
      "________________________________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)                  (None, None, None, 1280)   0             multiply[0][0]                          \n",
      "                                                                                conv2d[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "roi_input (InputLayer)                 [(None, None, 4)]          0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "roi_pooling_conv (RoiPoolingConv)      (1, 128, 7, 7, 1280)       0             multiply_1[0][0]                        \n",
      "                                                                                roi_input[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "time_distributed (TimeDistributed)     (1, 128, 62720)            0             roi_pooling_conv[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistributed)   (1, 128, 4096)             256905216     time_distributed[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "rpn_conv1 (Conv2D)                     (None, None, None, 256)    2949376       multiply_1[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistributed)   (1, 128, 4096)             16781312      time_distributed_1[0][0]                \n",
      "________________________________________________________________________________________________________________________\n",
      "rpn_out_class (Conv2D)                 (None, None, None, 9)      2313          rpn_conv1[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "rpn_out_regress (Conv2D)               (None, None, None, 36)     9252          rpn_conv1[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_class_16 (TimeDistributed)       (1, 128, 16)               65552         time_distributed_2[0][0]                \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_regress_16 (TimeDistributed)     (1, 128, 60)               245820        time_distributed_2[0][0]                \n",
      "========================================================================================================================\n",
      "Total params: 292,089,787\n",
      "Trainable params: 292,087,227\n",
      "Non-trainable params: 2,560\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 5 # len(train_images) # int(cfg.epoch_length)\n",
    "num_epochs = int(cfg.num_epochs)\n",
    "iter_num = 0\n",
    "\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "best_loss = np.Inf\n",
    "\n",
    "rpn_accuracy_for_epoch = []\n",
    "\n",
    "class_mapping_inv = {v: k for k, v in cfg.class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "P2433.png (1956, 1930, 3)\n",
      "P2433.png (1968, 1936, 3)\n",
      "success data_gen_train (1, 246, 242, 18) (1, 246, 242, 72)\n",
      "loss\n",
      "nan 7.668367862701416\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-63acf571bf17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIouS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroi_helpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_iou\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Faster-RCNN-for-Dota\\utils\\roi_helpers.py\u001b[0m in \u001b[0;36mcalc_iou\u001b[1;34m(R, img_data, C, class_mapping)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# (x1, y1, x2, y2) = R[ix, :]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch_num in range(num_epochs):\n",
    "        progbar = Progbar(epoch_length)\n",
    "        print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "        \n",
    "        for iter_num in range(epoch_length):\n",
    "            \n",
    "            X, Y, img_data, cache = next(data_gen_train)\n",
    "            print(\"success data_gen_train\", Y[0].shape, Y[1].shape)\n",
    "            \n",
    "\n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "            print(\"loss\")\n",
    "            print(loss_rpn[0], loss_rpn[1])\n",
    "\n",
    "            P_rpn = model_rpn.predict_on_batch(X) # (rpn cls, rpn regr)\n",
    "\n",
    "            result = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], cfg, 'tf', use_regr=True,\n",
    "                                            overlap_thresh=0.7,\n",
    "                                            max_boxes=256) # origin code is 300 but paper is set by 256 (128 - positive, 128 - negative)\n",
    "            \n",
    "\n",
    "            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            X2, Y1, Y2, IouS = roi_helpers.calc_iou(result, img_data, cfg, cfg.class_mapping)\n",
    "\n",
    "            if X2 is None:\n",
    "                print(\"X2 is None\", X2)\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"X2 is not None: \", X2.shape)\n",
    "\n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "            \n",
    "            if len(neg_samples) > 0:\n",
    "                neg_samples = neg_samples[0]\n",
    "            else:\n",
    "                neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0:\n",
    "                pos_samples = pos_samples[0]\n",
    "            else:\n",
    "                pos_samples = []\n",
    "            \n",
    "            if len(pos_samples) < cfg.num_rois // 2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, cfg.num_rois // 2, replace=False).tolist()\n",
    "\n",
    "            if len(neg_samples) + len(selected_pos_samples) > cfg.num_rois:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "            else:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, cfg.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "            selected_samples = selected_pos_samples + selected_neg_samples\n",
    "\n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, selected_samples, :]], [Y1[:, selected_samples, :], Y2[:, selected_samples, :]])\n",
    "            \n",
    "            ####\n",
    "            \n",
    "            print(\"img input:\", X.shape)\n",
    "            print(\"roi input:\", X2[:, selected_samples, :].shape, len(selected_samples))\n",
    "            print(X.shape, X2.shape, Y1.shape, Y2.shape, X.dtype, X2.dtype, Y1.dtype, Y2.dtype)\n",
    "\n",
    "            losses[iter_num, 0] = loss_rpn[1]\n",
    "            losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "            losses[iter_num, 2] = loss_class[1]\n",
    "            losses[iter_num, 3] = loss_class[2]\n",
    "            losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "            progbar.update(iter_num,\n",
    "                           [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                            ('detector_cls', np.mean(losses[:iter_num, 2])),\n",
    "                            ('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "\n",
    "        loss_rpn_cls = np.mean(losses[:, 0])\n",
    "        loss_rpn_regr = np.mean(losses[:, 1])\n",
    "        loss_class_cls = np.mean(losses[:, 2])\n",
    "        loss_class_regr = np.mean(losses[:, 3])\n",
    "        class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "        mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "\n",
    "        if cfg.verbose:\n",
    "            print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "            if mean_overlapping_bboxes == 0:\n",
    "                print('RPN is not producing bounding boxes that overlap the ground truth boxes.')\n",
    "                print('Check RPN settings or keep training.')\n",
    "                \n",
    "            print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "            print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "            print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "            print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "            print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "            print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "        curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "\n",
    "        if curr_loss < best_loss:\n",
    "            if cfg.verbose:\n",
    "                print('Total loss decreased from {} to {}, saving weights'.format(best_loss, curr_loss))\n",
    "            best_loss = curr_loss\n",
    "            model_all.save_weights(cfg.model_path)\n",
    "\n",
    "        rpn_accuracy_for_epoch = []\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_sum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.convert_to_tensor(np.array([i for i in range(2 * 2* 36)]))\n",
    "a2 = tf.convert_to_tensor(np.array([1000+i for i in range(2 * 2 * 36)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.reshape(a1, (2*2*9, 4))\n",
    "a2 = tf.reshape(a2, (2*2*9, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = K.expand_dims(a1, axis=-1)\n",
    "b2 = K.expand_dims(a2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = K.concatenate((b1, b2), axis=-1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = K.max(c, axis=-1)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(K.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfkljsadlkfjsad;fjsdlfj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.convert_to_tensor(np.array([i for i in range(2 * 2* 36)]))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = K.reshape(t, (2 * 2 * 9, 4))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = K.transpose(k)\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = K.reshape(t, (2, 2, 9, 4))\n",
    "k.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(k.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4 = k.shape\n",
    "s1, s2, s3, s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/2  \n",
    "P2379.png (2251, 2085, 3)\n",
    "P2379.png (2272, 2112, 3)\n",
    "success data_gen_train (1, 284, 264, 18) (1, 284, 264, 72)\n",
    "loss_cls (1, 284, 264, 18)\n",
    "loss_regr (1, 284, 264, 72)\n",
    "loss_cls (1, 284, 264, 18)\n",
    "loss_regr (1, 284, 264, 72)\n",
    "rpn train and predict (1, 284, 264, 9) (1, 284, 264, 36)\n",
    "img input: (1, 2272, 2112, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1930.png (2462, 1300, 3)\n",
    "rpn ground truth 419.92185068130493\n",
    "calc_rpn Error\n",
    "#calc_rpn Exception : can't multiply sequence by non-int of type 'float'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch 1/2\n",
    "5/5 [==============================] - 3270s 654s/step - rpn_cls: 6.2361 - rpn_regr: 0.7347 - detector_cls: 2.7627 - detector_regr: 0.2693\n",
    "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.9166666666666667\n",
    "- Classifier accuracy for bounding boxes from RPN: 0.7\n",
    "- Loss RPN classifier: 5.417903423309326\n",
    "- Loss RPN regression: 0.764133733510971\n",
    "- Loss Detector classifier: 2.743869400024414\n",
    "- Loss Detector regression: 0.1439718186855316\n",
    "- Elapsed time: 3269.942060947418\n",
    "- Total loss decreased from inf to 9.069878375530244, saving weights\n",
    "\n",
    "\n",
    "# Epoch 2/2\n",
    "5/5 [==============================] - 1960s 392s/step - rpn_cls: 5.6016 - rpn_regr: 0.7821 - detector_cls: 2.6116 - detector_regr: 0.3472\n",
    "Mean number of bounding boxes from RPN overlapping ground truth boxes: 1.1666666666666667\n",
    "\n",
    "- Classifier accuracy for bounding boxes from RPN: 0.9125\n",
    "- Loss RPN classifier: 4.953123617172241\n",
    "- Loss RPN regression: 0.8024014845490456\n",
    "- Loss Detector classifier: 2.5067588329315185\n",
    "- Loss Detector regression: 0.22378002405166625\n",
    "- Elapsed time: 1962.5114130973816\n",
    "- Total loss decreased from 9.069878375530244 to 8.486063958704472, saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, aug, cache = next(data_gen_train)\n",
    "y_rpn_cls, y_rpn_regr = Y\n",
    "y_rpn_overlap, y_rpn_regr = cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = os.path.join('..' , 'data', 'train', 'images')\n",
    "colors = []\n",
    "grays = []\n",
    "\n",
    "for file in tqdm(os.listdir(base)):\n",
    "    img = tf.io.read_file(os.path.join(base, file))\n",
    "    img = tf.image.decode_image(img)\n",
    "    \n",
    "    if img.shape[-1] == 3:\n",
    "        colors.append(img.shape)\n",
    "    elif img.shape[-1] == 1:\n",
    "        grays.append(img.shape)\n",
    "    else:\n",
    "        print(\"ERROR : {}\".format(image.shape))\n",
    "    \n",
    "#     print(\"{} \\t {}\".format(file, img.shape))\n",
    "    \n",
    "print(\"colors : {} , grays: {}\".format(len(colors), len(grays)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.path.join('..' , 'data', 'train', 'images')\n",
    "img = tf.io.read_file(os.path.join(base, 'P1200.png'))\n",
    "img = tf.image.decode_image(img)\n",
    "print(img.shape)\n",
    "\n",
    "img = tf.image.grayscale_to_rgb(img)\n",
    "print(img.shape)\n",
    "\n",
    "# cv2.imwrite('img.jpg', img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.pad(img, ((0, 0), (0, 16), (0, 0)), \"CONSTANT\", constant_values=0)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "img = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_cls, rpn_regr = model_rpn.predict(img)\n",
    "print(rpn_cls.shape, rpn_regr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_cls_args = np.argwhere(rpn_cls >= 0.6)\n",
    "print(rpn_cls_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for args in rpn_cls_args:\n",
    "    print(rpn_regr[0, args[1], args[2], args[3]*4: args[3]*4 + 4])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpn_regr, rpn_cls, class_cls = model_all.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.io.read_file(os.path.join('..' , 'data', 'train', 'images', 'P1311.png'))\n",
    "img = tf.image.decode_image(img)\n",
    "\n",
    "if len(img.shape) == 2 or img.shape[-1] == 1:\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "\n",
    "if img.shape[0] % 2 or img.shape[1] % 2:\n",
    "    pad_w, pad_h = 16 - img.shape[0] % 16, 16 - img.shape[1] % 16\n",
    "\n",
    "    if pad_h == 16:\n",
    "        pad_h = 0\n",
    "    if pad_w == 16:\n",
    "        pad_w = 0\n",
    "\n",
    "    paddings = tf.constant([[0, pad_h], [0, pad_w]])\n",
    "\n",
    "    img = tf.pad(img, paddings, \"CONSTANT\", constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
